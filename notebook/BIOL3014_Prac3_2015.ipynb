{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython notebook created by Mikael Bodén. Material is derived from BIOL3014 Practical 3 (2014).\n",
    "\n",
    "Bug fixes: m.boden@uq.edu.au\n",
    "\n",
    "Source: https://github.com/UQ-BIOL3014/Practical3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOL3014/BINF7000 Practical 3\n",
    "\n",
    "## Prediction and machine learning\n",
    "---\n",
    "\n",
    "* **Due:** 11AM 26/08/2015\n",
    "* **Revision:** 1\n",
    "* **Marks:** \n",
    "    * **BIOL3014** - 8 marks. \n",
    "    * **BINF7000** - 12 marks.\n",
    "---\n",
    "\n",
    "\n",
    "### Objectives \n",
    "\n",
    "In this practical:\n",
    "* You learn about the problem of predicting protein secondary structure from sequence, which is similar to many other problems in bioinformatics\n",
    "* You work with machine learning algorithms, in particular the so-called Naive Bayes' classifier\n",
    "* You get practical experience in evaluating prediction performance so you can compare different approaches to solving a problem\n",
    "---\n",
    "\n",
    "\n",
    "### Submission requirements\n",
    "\n",
    "Please export this IPython notebook (with written answers & completed code) to `STUDENTNUMBER_P3.ipynb` notebook and submit it via the BlackBoard portal. See the screenshot below:\n",
    "\n",
    "![alt text](export_workbook.png \"Exporting your workbook\")\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "### Resources\n",
    "\n",
    "#### Python resources:\n",
    "* The UQ Bioinformatics Python Guide (on Blackboard)\n",
    "* The [Python 2 documentation]. For those unfamiliar with Python the [Official tutorial] is recommended\n",
    "* The software carpentry [Novice python lessons]\n",
    "\n",
    "[Python 2 documentation]: https://docs.python.org/2/\n",
    "[Official tutorial]: https://docs.python.org/2/tutorial/index.html\n",
    "[Novice python lessons]: http://swcarpentry.github.io/python-novice-inflammation/\n",
    "\n",
    "####Relevant modules:\n",
    "* `sym.py` (see `DSSP3_Alphabet`; the three-letter DSSP code)\n",
    "* `prob.py` (see `NaiveBayes`; an implementation of classification using Bayes' rule)\n",
    "* `sequence.py` (for loading sequence data on FASTA format)\n",
    "* `ml.py` (see `NN`; an implementation of neural network; there's also accuracy metrics here)\n",
    "* `spred.py` (examples and `NN` wrapper for prediction models based on sequence windows)\n",
    "\n",
    "#### Other:\n",
    "* [IPython Notebook markdown cheatsheet]\n",
    "\n",
    "[IPython Notebook markdown cheatsheet]: https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet#links\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "For all example code to work, make sure you import all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sym   # see DSSP3_Alphabet; the three-letter DSSP code\n",
    "import prob     # see NaiveBayes; an implementation of classification using Bayes' rule\n",
    "import sequence # for loading sequence data on FASTA format\n",
    "import ml       # see NN; an implementation of neural network\n",
    "import spred    # examples and NN wrapper for prediction models based on sequence windows\n",
    "import numpy    # Numerical Python (standard library; you need numpy installed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A (8 marks)\n",
    "Complete all exercises in Part 1. You must provide responses to requests highlighted in <span style=\"color:red\">**bold**</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naïve Bayes classifier determines a probability of the form\n",
    "\n",
    "$P(C | F_1, F_2, …, F_n)$\n",
    "\n",
    "where $F_1$, $F_2$, …, $F_n$ are “features” and $C$ is the class, each represented by a probability distribution. We will discuss what goes into the calculation of $P(C | F_1, F_2, …, F_n)$ below. Naïve Bayes classifiers can be depicted in the following way.\n",
    "\n",
    "![alt text](nb.png \"Naive Bayes' classifier\")\n",
    "\n",
    "You will construct a naïve Bayes classifier for secondary structure prediction (where your class is secondary structure as defined by 3-class DSSP and your features are the amino acids in a window surrounding the residue for which the secondary structure applies). \n",
    "\n",
    "You will require data to train it and test it to gauge what the accuracy is for truly novel proteins.\n",
    "\n",
    "You are requested to work with secondary structure data that has been prepared for you. The data originate from PDB (Protein Data Bank; http://www.pdb.org) via PDBFINDER2 (http://swift.cmbi.ru.nl/gv/pdbfinder/). We randomly selected about 20% of all proteins, and then reduced this set to only include sequences with less than 20% sequence identity (according to blastclust; http://blast.ncbi.nlm.nih.gov). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Exercise 1. Inspect data sets. \n",
    "The data directory contains a protein set (`prot2.fa`) and the corresponding secondary structure set (`sstr3.fa`). Start Python and load the files after importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prot = sequence.readFastaFile('prot2.fa', sym.Protein_Alphabet)\n",
    "sstr = sequence.readFastaFile('sstr3.fa', sym.DSSP3_Alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(a) In the cell below, write a small piece of code to verify that the two files contain entries for the same ~2500 proteins**</span>: Count the sequences, check that the names are the same and in the same order in the two files, check that each amino acid residue in the first correspond to a 3-class secondary structure element in the second file (H: Helix, E: Strand, C: Coil). In other words, check that the sequences of amino acids and of secondary structure letters have the same size and that the latter only use the letters H, E and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide each data set in half, corresponding to a train and a test set respectively, e.g. divide them into distinct sets, using odd and even number indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prot_trn = prot[0::2] # even-numbered indices; starting at 0, then every second protein sequence\n",
    "prot_tst = prot[1::2] # odd-numbered indices; starting at 1, then every second protein sequence\n",
    "sstr_trn = sstr[0::2] # even-numbered indices; as above, but now for secondary structure sequences\n",
    "sstr_tst = sstr[1::2] # odd-numbered indices; as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Exercise 2. Present data as \"windows\". \n",
    "We have prepared a module `spred` with a method `slidewin` to generate multiple sub-sequences corresponding to a “moving-window” of a specified width (`W`). The method `slidewin` is short, so feel free to check it out by glancing at the code you have been using at ["uqbinfpy"]. Next, we verify that it generates appropriate `W=5` sub-sequences for `prot_trn[0]`. "
    "["uqbinfpy"]: https://github.com/UQ-BIOL3014/uqbinfpy/tree/master/uqbinfpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = 5\n",
    "windows = spred.slidewin(prot_trn[0], W)\n",
    "for window in windows:\n",
    "    print window,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(a) In the cell below, write Python code to print out the answers to the following questions**</span>:\n",
    "- What is the length of prot_trn[0]? \n",
    "- What is the number of sub-sequences? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(b) Explain why the two numbers differ. Provide a formula involving `W` to determine one from the other.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Exercise 3. Create a probabilistic classifier of secondary structure. \n",
    "We are leaving the training and test data aside for a moment to focus on the classifier, which can be created like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = prob.NaiveBayes([sym.Protein_Alphabet for _ in range(W)], sym.DSSP3_Alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prob.NaiveBayes` class has two interesting fields, which will collectively determine what the instance `nb` \"predicts\". One for the distribution over the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print nb.classprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is printed above is an instance of the class `prob.Distrib`, and it has yet to be \"trained\".\n",
    "There is another field for the conditional probabilities in `prob.NaiveBayes`. Note that there is a `prob.Distrib` over amino acids, for each class, and for each position in the input window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in nb.condprobs:\n",
    "    print 'Class', c \n",
    "    for i in range(len(nb.condprobs[c])):\n",
    "        print 'Input', i, nb.condprobs[c][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the posterior class probability for a `key` with a list of symbols (e.g. a text-string such as `'YECKA'`) this is what `prob.NaiveBayes` does. <span style=\"color:red\">**(a) Express this as a formula of how to calculate $P(C | F_1, F_2, ..., F_n)$ where $n$ is the length of the key**</span>.\n",
    "```python\n",
    "def __getitem__(self, key):\n",
    "    \"\"\" Determine and return the class probability GIVEN \n",
    "        a specified n-tuple of feature values.\n",
    "        The class probability is given as an instance of Distrib. \"\"\"\n",
    "    out = Distrib(self.classprob.alpha)\n",
    "    for outsym in self.classprob.getSymbols():\n",
    "        condprob = self.condprobs[outsym]\n",
    "        prob = self.classprob[outsym]\n",
    "        for i in range(len(key)):\n",
    "            prob *= condprob[i][key[i]] or 0.0\n",
    "        out.observe(outsym, prob)\n",
    "    return out\n",
    "```\n",
    "When `__getitem__` is defined for a class, it should implement an \"index\" or \"key\" (like a dictionary). The index in the example below is `'YECKA'` (and `'YECLA'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print nb['YECKA']\n",
    "print nb['YECLA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has not yet seen any data so it's prediction (the posterior class probability) will reflect this. Let's train it minimally by \"observing\" a secondary structure Coil, i.e. `'C'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb.classprob.observe('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(b) Check the posterior class probability for `'YECKA'` again, and report what the prediction is and explain why this is the correct output**</span>. Make reference to the definition of `__getitem__` above in your response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above trains only the secondary structure class probability distribution. It does not change the conditional feature distributions. If wanted to associate the observation of Coil above, with that of seeing a Lysine (`'K'`) in position 4 (index 3), we could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb.condprobs['C'][3].observe('K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(c) Check the posterior class probability for `'YECKA'` a third time, and for `'YECLA'`. Explain the difference you see.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we wrote the `prob.NaiveBayes` class, we anticipated that training would involve observations about _both_ class and feature probabilities, so we defined the method `prob.NaiveBayes.observe`:\n",
    "```python\n",
    "    def observe(self, inpseq, outsym):\n",
    "        \"\"\" Record an observation of an input sequence of feature values that belongs to a class.\n",
    "            inpseq: sequence/list of feature values, e.g. 'ATG'\n",
    "            outsym: the class assigned to these feature values. \"\"\"\n",
    "        condprob = self.condprobs[outsym]\n",
    "        for i in range(len(inpseq)):\n",
    "            condprob[i].observe(inpseq[i])\n",
    "        self.classprob.observe(outsym)\n",
    "```\n",
    "So, to associate `'YECLA'` with Helix (`'H'`), we could simply use that, like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb.observe('YECLA','H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#####Exercise 4. Training the Naive Bayes classifier\n",
    "Back to the data sets we loaded and processed earlier in Exercise 2. We are now going to train the classifier using extensive data; thousands of sequences, each with hundreds of amino acids. The probabilities that result from this data are based on large counts.\n",
    "\n",
    "We are going to loop through all sequences in the training set, and for each sequence loop through all possible input windows. The code below takes a few seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(prot_trn)):               # for each sequence\n",
    "    subseqs = spred.slidewin(prot_trn[i], W) # construct sub-sequences (windows)\n",
    "    subtarg = sstr_trn[i][W/2:-W/2+1]        # secondary structure target for each sub-sequence\n",
    "    for j in range(len(subseqs)):\n",
    "        nb.observe(subseqs[j], subtarg[j])   # let NB observe each sub-sequence with its corresponding target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#####Exercise 5. What did the classifier learn? \n",
    "\n",
    "Inspect the 5-window classifier to determine the effect Glutamic acid (E), Proline (P) and Glycine (G) have on 3-class secondary structure at different positions in a window. Have a look at the implementation of the classifier (prob.py). Note that you can retrieve the relevant probabilities like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print nb.condprobs['H'][2]        # P(aa|ss=H,col=2)\n",
    "print nb.condprobs['H'][2]['E']   # P(aa=E|ss=H,col=2)\n",
    "col = 0\n",
    "for aa in nb.condprobs['H']:      # P(aa|ss=H,col)\n",
    "    print \"E @ col %d is %5.3f\" % (col, aa['E'])\n",
    "    col += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these probabilities to the background, i.e. frequencies of amino acids in the test and training sequences (see our old friend `prob.Distrib`). <span style=\"color:red\">**(a) Report the propensities of these three amino acids in the three classes when they appear in the middle position of the window, compared to their random distribution in the box below**</span>. Provide either your calculations, or the code that does the calculation and printing out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(b) According to your W = 5 classifier, what is the probability of seeing a glutamic acid at the centre of the window in a Helix, i.e. $P(aa={\\tt E}|ss={\\tt H},col={\\tt 2})$?**</span> Provide code or calculations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(c) What is the probability of strand, if there is a Glycine in the first column of a 5-residue window, i.e. $P(ss={\\tt E}|aa={\\tt G}, col={\\tt 0})$?**</span>\n",
    "\n",
    "To answer this, you will need to access the distributions in the class `prob.NaiveBayes`, and do some extra calculations. Provide code or calculations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(d) Which is the most probable secondary structure if there is a Proline in the middle column, i.e. $P(ss|aa={\\tt P}, col={\\tt W/2})$?**</span>\n",
    "\n",
    "To answer this, you again need to think more carefully and make some extra calculations. You can answer this without using a whole window because the Naïve Bayes classifier treats positions independently given the class. Provide code or calculations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#####Exercise 6. Evaluating prediction accuracy\n",
    "In this section we will evaluate how well your classifier is doing on the test data. \n",
    "\n",
    "First, look up [“Confusion Matrix”] in Wikipedia and read this section carefully. (You will not be able to work out the exercises below unless you understand what it is.)\n",
    "We will now construct an all-zero confusion matrix from your test set.\n",
    "\n",
    "[“Confusion Matrix”]: https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = numpy.zeros((len(sym.DSSP3_Alphabet), len(sym.DSSP3_Alphabet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the classifier to predict the class posterior for every single sequence and every window in the test set. In this loop of loops, we collect the predictions: always the class with the _largest_ probability.\n",
    "(Note: testing takes some time also; ~10 seconds on my laptop.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(prot_tst)):\n",
    "    subseqs = spred.slidewin(prot_tst[i], W)\n",
    "    subtarg = sstr_tst[i][W/2:-W/2+1]\n",
    "    for j in range(len(subseqs)):\n",
    "        out = nb[subseqs[j]]\n",
    "        c_targ = sym.DSSP3_Alphabet.index(subtarg[j])\n",
    "        c_pred = out.prob().index(max(out.prob()))\n",
    "        cm[c_targ, c_pred] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(a) Print your matrix, with labels for the three classes. Report which class (of the three) is more difficult to predict.**</span> Easiest is probably to specify the code to print out the answer, but you may provide it in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix many metrics can be computed, e.g. $Q_3$\n",
    "![alt text](11-05.jpg \"$Q_3$ metric for prediction accuracy\")\n",
    "The module `ml.py` contains an implementation if you would like to compute it programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Qk, Q = ml.Qk(cm, symbol.DSSP3_Alphabet)\n",
    "print Qk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have only looked at one window size (`W=5`) so far.\n",
    "<span style=\"color:red\">**(b) Investigate what window size that gives you the greatest $Q_3$. Report this size. Provide code.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B (4 marks; BINF7000 only)\n",
    "Complete all exercises in Part B. You must provide responses to requests highlighted in <span style=\"color:red\">**bold**</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#####Exercise 7. Literature search\n",
    "When we created the data sets, we removed all sequences that shared more than 20% sequence similarity. This is sometimes referred to as “sequence redundancy reduction”. <span style=\"color:red\">**(a) Explain why this is a good idea.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different machine learning approaches to predicting secondary structure from sequence, including neural networks (NNs) and support-vector machines (SVMs). NNs require inputs to be numeric (and this is how most SVMs operate too). <span style=\"color:red\">**Below, discuss how amino acids can be presented numerically, so that windows of a protein sequence can be presented to a NN or SVM.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**(b) In the box below, describe an example neural network that could process the numeric input and output, to predict secondary structure.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Exercise 8. Use predictions\n",
    "Select any PDB entry—avoiding those that are in the data set above. For example, retrieve “3ZXQ” (PDB database) which was added after I constructed the FASTA files you have been using. Download the atomic description file (known as the “PDB file”). Use DSSP (http://www.cmbi.ru.nl/dssp.html) to find its secondary structure. <span style=\"color:red\">**(a) In the box below, declare a Python variable `myseq_aa` which is assigned the amino acid sequence, and another `myseq_dssp` which is assigned the DSSP assignment for its structure.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myseq_aa = sequence.Sequence(\"Insert your AA sequence here\", sym.Protein_Alphabet, name = \"Name here\")\n",
    "myseq_dssp = sequence.Sequence(\"Insert the corresponding DSSP sequence\", sym.DSSP3_Alphabet, name = \"Name here\")\n",
    "subseqs = spred.slidewin(myseq_aa, W)\n",
    "subtarg = myseq_dssp[W/2:-W/2+1]\n",
    "for j in range(len(subseqs)):\n",
    "    out = nb[subseqs[j]]\n",
    "    print 'Input is', subseqs[j], 'Output is', out, 'Target is', subtarg[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:red\">**(b) In the box below, write a report on the following:**</span> How well does your Naïve Bayes predictor perform on this particular protein in terms of its secondary structure? Visualize your protein in 3D using PDB’s built-in tools or using stand-alone tools such as PyMol, chimera, or others (include a screenshot or a rendered image generated by these software in your report; place it in the notebook directory and link it in below). Manually/informally project predictions to 3D: Identify and discuss what structures that are easy/difficult to identify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
